import os
import json
import argparse
from pathlib import Path
import openai
import tqdm
import time
import datetime
import concurrent.futures
from concurrent.futures import ThreadPoolExecutor
import threading

# Thread-local storage for OpenAI clients
thread_local = threading.local()

def get_openai_client():
    """Get or create a thread-local OpenAI client"""
    if not hasattr(thread_local, "client"):
        api_key = load_api_key()
        thread_local.client = openai.OpenAI(api_key=api_key)
    return thread_local.client

def load_api_key():
    """Load OpenAI API key from .open_ai_key file"""
    key_path = Path.home() / ".open_ai_key"
    if not key_path.exists():
        raise FileNotFoundError(f"API key file not found at {key_path}. Please create this file with your OpenAI API key.")
    
    with open(key_path, 'r') as f:
        api_key = f.read().strip()
    
    if not api_key:
        raise ValueError("API key is empty. Please add your OpenAI API key to the .open_ai_key file.")
    
    return api_key

def load_custom_vocabulary(vocab_file=None):
    """Load custom vocabulary from a JSON file if provided"""
    if not vocab_file or not os.path.exists(vocab_file):
        return None
    
    try:
        with open(vocab_file, 'r') as f:
            vocab_data = json.load(f)
        
        # Create a prompt from the vocabulary
        if isinstance(vocab_data, list):
            # If it's a simple list of terms
            terms = ", ".join(vocab_data)
            prompt = f"Some terms you may encounter: {terms}."
        elif isinstance(vocab_data, dict):
            # If it's a dictionary with categories
            prompt_parts = []
            for category, terms in vocab_data.items():
                if isinstance(terms, list):
                    terms_str = ", ".join(terms)
                    prompt_parts.append(f"{category}: {terms_str}")
            
            prompt = "You may encounter these terms: " + "; ".join(prompt_parts) + "."
        else:
            prompt = None
        
        return prompt
    except Exception as e:
        print(f"Error loading custom vocabulary: {str(e)}")
        return None

def process_file(args):
    """Process a single file for transcription - designed for parallel execution"""
    filename, source_folder, output_folder, force_reprocess, file_index, total_files, progress_callback, custom_vocab_prompt, file_metadata = args
    
    # Extract metadata
    speaker = file_metadata.get("speaker")
    subject = file_metadata.get("subject")
    topic = file_metadata.get("topic")
    ping_type = file_metadata.get("ping_type")
    
    # Get the full path to the MP3 file
    full_path = os.path.join(source_folder, filename)
    
    # Determine output JSON path
    if output_folder:
        output_json_path = os.path.join(output_folder, f"{filename}.json")
    else:
        output_json_path = os.path.join(source_folder, f"{filename}.json")
    
    # Update progress
    if progress_callback:
        progress_callback(
            file=filename, 
            current=file_index, 
            total=total_files,
            status=f"Processing {file_index+1}/{total_files}: {filename}"
        )
    else:
        print(f"Processing {file_index+1}/{total_files}: {filename}")
    
    # Get file stats for date
    file_date = None
    try:
        stats = os.stat(full_path)
        if hasattr(stats, 'st_birthtime'):  # macOS and some systems
            timestamp = stats.st_birthtime
        else:  # Linux and others
            timestamp = stats.st_mtime
        file_date = datetime.datetime.fromtimestamp(timestamp).strftime("%Y-%m-%d")
    except:
        pass
    
    # Check if we can use an existing transcription
    if os.path.exists(output_json_path) and not force_reprocess:
        try:
            with open(output_json_path, 'r') as f:
                existing_transcription = json.load(f)
            
            # Extract the transcription text from the existing file
            transcription_text = ""
            
            # Try to get text from different possible formats
            if "text" in existing_transcription:
                transcription_text = existing_transcription["text"]
            elif "segments" in existing_transcription:
                # Concatenate all segment texts
                segments = existing_transcription["segments"]
                if isinstance(segments, list):
                    transcription_text = " ".join([segment.get("text", "") for segment in segments])
            
            # Return data for consolidated JSON
            result_data = {
                "status": "skipped",
                "filename": filename,
                "transcription_data": {
                    "date": file_date,
                    "voiceline_id": existing_transcription.get("voiceline_id", os.path.splitext(filename)[0]),
                    "transcription": transcription_text
                },
                "metadata": file_metadata
            }
            
            if progress_callback:
                progress_callback(status=f"Skipping {filename} (already transcribed)")
            else:
                print(f"Skipping {filename} (already transcribed)")
            
            return result_data
            
        except Exception as e:
            # If there's an error reading the existing file, we'll reprocess it
            if progress_callback:
                progress_callback(status=f"Error reading existing transcription for {filename}, will reprocess: {str(e)}")
            else:
                print(f"Error reading existing transcription for {filename}, will reprocess: {str(e)}")
    
    try:
        # Check if the file exists
        if not os.path.exists(full_path):
            error_msg = f"Error: File not found: {full_path}"
            if progress_callback:
                progress_callback(error=error_msg)
            else:
                print(error_msg)
            return {
                "status": "failed", 
                "filename": filename, 
                "error": error_msg,
                "metadata": file_metadata
            }
        
        # Get thread-local OpenAI client
        client = get_openai_client()
        
        # Transcribe the audio using OpenAI API
        with open(full_path, "rb") as audio_file:
            # Call Whisper API with the thread-local client
            # Add the custom vocabulary prompt if available
            transcription_args = {
                "model": "whisper-1",
                "file": audio_file,
                "response_format": "verbose_json",
                "timestamp_granularities": ["segment"]
            }
            
            # Add prompt if we have custom vocabulary
            if custom_vocab_prompt:
                transcription_args["prompt"] = custom_vocab_prompt
                
            response = client.audio.transcriptions.create(**transcription_args)
            
            # Convert response to dictionary if it's not already
            if not isinstance(response, dict):
                response = response.model_dump()
        
        # Extract filename without extension to use as voiceline_id
        filename_without_ext = os.path.splitext(filename)[0]
        
        # Format the result in the requested structure
        output_data = {
            "voiceline_id": filename_without_ext,
            "timestamp": datetime.datetime.now().isoformat(),
            "segments": []
        }
        
        # Add segments with simplified structure
        for idx, segment in enumerate(response.get("segments", [])):
            output_data["segments"].append({
                "start": segment.get("start", 0),
                "end": segment.get("end", 0),
                "text": segment.get("text", ""),
                "part": idx + 1
            })
        
        # Save the transcription to a JSON file
        with open(output_json_path, 'w') as f:
            json.dump(output_data, f, indent=2)
        
        # Return success with data for consolidated JSON
        return {
            "status": "success", 
            "filename": filename,
            "transcription_data": {
                "date": file_date,
                "voiceline_id": filename_without_ext,
                "transcription": response.get("text", "")
            },
            "metadata": file_metadata
        }
        
    except Exception as e:
        error_msg = f"Error transcribing {filename}: {str(e)}"
        if progress_callback:
            progress_callback(error=error_msg)
        else:
            print(error_msg)
        return {
            "status": "failed", 
            "filename": filename, 
            "error": error_msg,
            "metadata": file_metadata
        }

def transcribe_voice_files(input_json_path, source_folder, force_reprocess=False, progress_callback=None, output_folder=None, consolidated_json_path=None, max_workers=5, custom_vocab_file=None):
    """
    Transcribe all MP3 files mentioned in the JSON file using OpenAI Whisper API.
    Creates a JSON file for each MP3 with the transcription results in the specified format.
    
    Args:
        input_json_path (str): Path to the input JSON file
        source_folder (str): Path to the source folder containing the MP3 files
        force_reprocess (bool): Whether to reprocess files that already have transcriptions
        progress_callback (function): Optional callback function for progress updates
        output_folder (str, optional): Path to the output folder for transcription JSON files
        consolidated_json_path (str, optional): Path to save a consolidated JSON file with all transcriptions
        max_workers (int): Maximum number of parallel workers for transcription (default: 5)
        custom_vocab_file (str, optional): Path to a JSON file containing custom vocabulary
    
    Returns:
        dict: Statistics about the transcription process
    """
    try:
        # Validate API key first
        api_key = load_api_key()
    except Exception as e:
        error_msg = f"Error loading API key: {str(e)}"
        if progress_callback:
            progress_callback(error=error_msg)
        else:
            print(error_msg)
        return {"error": error_msg}
    
    # Load custom vocabulary if provided
    custom_vocab_prompt = load_custom_vocabulary(custom_vocab_file)
    if custom_vocab_prompt and progress_callback:
        progress_callback(status=f"Loaded custom vocabulary prompt: {custom_vocab_prompt[:100]}...")
    elif custom_vocab_prompt:
        print(f"Loaded custom vocabulary prompt: {custom_vocab_prompt[:100]}...")
    
    # Create output folder if specified and it doesn't exist
    if output_folder:
        os.makedirs(output_folder, exist_ok=True)
        if progress_callback:
            progress_callback(status=f"Created output folder: {output_folder}")
        else:
            print(f"Created output folder: {output_folder}")
    
    # Load the input JSON file
    try:
        with open(input_json_path, 'r') as f:
            data = json.load(f)
    except Exception as e:
        error_msg = f"Error loading JSON file: {str(e)}"
        if progress_callback:
            progress_callback(error=error_msg)
        else:
            print(error_msg)
        return {"error": error_msg}
    
    # Collect all unique MP3 files with their metadata
    mp3_files_with_metadata = []
    
    # Process each speaker
    for speaker, subjects in data.items():
        # Process each subject
        for subject, topics in subjects.items():
            # Process each topic
            for topic, files in topics.items():
                # Handle special case for "Pings" category
                if topic == "Pings":
                    for ping_type, ping_files in files.items():
                        for file_entry in ping_files:
                            # Check if the file entry is a dictionary (new format) or a string (old format)
                            if isinstance(file_entry, dict) and 'filename' in file_entry:
                                filename = file_entry['filename']
                                # Store original path if available
                                original_path = file_entry.get('file_path', '')
                            else:
                                filename = file_entry
                                original_path = ''
                            
                            # Store file with its metadata
                            mp3_files_with_metadata.append({
                                "filename": filename,
                                "metadata": {
                                    "speaker": speaker,
                                    "subject": subject,
                                    "topic": "Pings",
                                    "ping_type": ping_type,
                                    "original_path": original_path
                                }
                            })
                else:
                    for file_entry in files:
                        # Check if the file entry is a dictionary (new format) or a string (old format)
                        if isinstance(file_entry, dict) and 'filename' in file_entry:
                            filename = file_entry['filename']
                            # Store original path if available
                            original_path = file_entry.get('file_path', '')
                        else:
                            filename = file_entry
                            original_path = ''
                        
                        # Store file with its metadata
                        mp3_files_with_metadata.append({
                            "filename": filename,
                            "metadata": {
                                "speaker": speaker,
                                "subject": subject,
                                "topic": topic,
                                "ping_type": None,
                                "original_path": original_path
                            }
                        })
    
    total_files = len(mp3_files_with_metadata)
    status_msg = f"Found {total_files} unique MP3 files to transcribe"
    if progress_callback:
        progress_callback(status=status_msg, total=total_files)
    else:
        print(status_msg)
    
    # Statistics counters
    successful = 0
    failed = 0
    skipped = 0
    
    # Create a thread pool for parallel processing
    status_msg = f"Starting transcription with {max_workers} parallel workers"
    if progress_callback:
        progress_callback(status=status_msg)
    else:
        print(status_msg)
    
    # Prepare arguments for each file
    file_args = [
        (
            file_info["filename"], 
            source_folder, 
            output_folder, 
            force_reprocess, 
            i, 
            total_files, 
            progress_callback, 
            custom_vocab_prompt,
            file_info["metadata"]
        )
        for i, file_info in enumerate(mp3_files_with_metadata)
    ]
    
    # Process files in parallel
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        results = list(executor.map(process_file, file_args))
    
    # Process results and build structured consolidated data
    consolidated_data = {}
    
    for result in results:
        if result["status"] == "success":
            successful += 1
        elif result["status"] == "skipped":
            skipped += 1
        else:  # failed
            failed += 1
            continue  # Skip failed files in consolidated output
        
        # Only include successful and skipped files in consolidated output
        if consolidated_json_path and "transcription_data" in result:
            # Extract metadata
            metadata = result["metadata"]
            speaker = metadata["speaker"]
            subject = metadata["subject"]
            topic = metadata["topic"]
            ping_type = metadata["ping_type"]
            
            # Initialize speaker if not exists
            if speaker not in consolidated_data:
                consolidated_data[speaker] = {}
            
            # Initialize subject if not exists
            if subject not in consolidated_data[speaker]:
                consolidated_data[speaker][subject] = {}
            
            # Handle special case for Pings
            if topic == "Pings":
                # Initialize Pings category if not exists
                if "Pings" not in consolidated_data[speaker][subject]:
                    consolidated_data[speaker][subject]["Pings"] = {}
                
                # Initialize ping type if not exists
                if ping_type not in consolidated_data[speaker][subject]["Pings"]:
                    consolidated_data[speaker][subject]["Pings"][ping_type] = []
                
                # Add the file with transcription
                consolidated_data[speaker][subject]["Pings"][ping_type].append({
                    "filename": result["filename"],
                    "date": result["transcription_data"]["date"],
                    "voiceline_id": result["transcription_data"]["voiceline_id"],
                    "transcription": result["transcription_data"]["transcription"]
                })
            else:
                # Initialize topic if not exists
                if topic not in consolidated_data[speaker][subject]:
                    consolidated_data[speaker][subject][topic] = []
                
                # Add the file with transcription
                consolidated_data[speaker][subject][topic].append({
                    "filename": result["filename"],
                    "date": result["transcription_data"]["date"],
                    "voiceline_id": result["transcription_data"]["voiceline_id"],
                    "transcription": result["transcription_data"]["transcription"]
                })
    
    # Save consolidated JSON if requested
    if consolidated_json_path and consolidated_data:
        try:
            # Create directory if it doesn't exist
            os.makedirs(os.path.dirname(os.path.abspath(consolidated_json_path)), exist_ok=True)
            
            # Save the consolidated data
            with open(consolidated_json_path, 'w') as f:
                json.dump(consolidated_data, f, indent=2)
            
            # Count total entries
            total_entries = 0
            for speaker, subjects in consolidated_data.items():
                for subject, topics in subjects.items():
                    for topic, files in topics.items():
                        if topic == "Pings":
                            for ping_type, ping_files in files.items():
                                total_entries += len(ping_files)
                        else:
                            total_entries += len(files)
            
            if progress_callback:
                progress_callback(status=f"Saved consolidated transcriptions to {consolidated_json_path} with {total_entries} entries in original structure")
            else:
                print(f"Saved consolidated transcriptions to {consolidated_json_path} with {total_entries} entries in original structure")
        except Exception as e:
            error_msg = f"Error saving consolidated JSON: {str(e)}"
            if progress_callback:
                progress_callback(error=error_msg)
            else:
                print(error_msg)
    
    # Final statistics
    stats = {
        "successful": successful,
        "failed": failed,
        "skipped": skipped,
        "total": total_files
    }
    
    summary = (
        f"\nTranscription complete:\n"
        f"  - Successfully transcribed: {successful}\n"
        f"  - Failed: {failed}\n"
        f"  - Skipped (already transcribed): {skipped}\n"
        f"  - Total: {total_files}"
    )
    
    if progress_callback:
        progress_callback(status=summary, complete=True, stats=stats)
    else:
        print(summary)
    
    return stats

def main():
    parser = argparse.ArgumentParser(description='Transcribe voice files using OpenAI Whisper API')
    parser.add_argument('--input-json', required=True, help='Path to the input JSON file')
    parser.add_argument('--source-folder', required=True, help='Path to the source folder containing the MP3 files')
    parser.add_argument('--output-folder', help='Path to the output folder for transcription JSON files')
    parser.add_argument('--consolidated-json', help='Path to save a consolidated JSON file with all transcriptions')
    parser.add_argument('--force', action='store_true', help='Force reprocessing of files that already have transcriptions')
    parser.add_argument('--workers', type=int, default=5, help='Number of parallel workers for transcription (default: 5)')
    parser.add_argument('--custom-vocab', help='Path to a JSON file containing custom vocabulary for better recognition')
    
    args = parser.parse_args()
    
    transcribe_voice_files(
        args.input_json,
        args.source_folder,
        args.force,
        output_folder=args.output_folder,
        consolidated_json_path=args.consolidated_json,
        max_workers=args.workers,
        custom_vocab_file=args.custom_vocab
    )

if __name__ == "__main__":
    main() 